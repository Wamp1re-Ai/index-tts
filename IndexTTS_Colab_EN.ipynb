{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/index-tts/index-tts/blob/feat/english-colab-notebook/IndexTTS_Colab_EN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndexTTS: Zero-Shot Text-To-Speech on Colab (English UI)\n",
    "\n",
    "This notebook allows you to run the IndexTTS system in Google Colab. It will clone the repository, install dependencies, download models, and start the Gradio web UI. The UI will be in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the IndexTTS repository\n",
    "!git clone https://github.com/index-tts/index-tts.git\n",
    "%cd index-tts\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "This step installs `ffmpeg` (required for audio processing) and all the Python packages listed in `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ffmpeg\n",
    "!apt-get update && apt-get install -y ffmpeg\n",
    "\n",
    "# Install uv for faster package installation\n",
    "!pip install uv\n",
    "\n",
    "# Install Python dependencies using uv\n",
    "# Note: pynini can sometimes have installation issues.\n",
    "# The original repo suggests `conda install -c conda-forge pynini==2.1.5` for Windows.\n",
    "# For Colab (Linux), pip/uv should generally work. If issues arise with pynini,\n",
    "# specific compatible versions or alternative installation methods might be needed.\n",
    "!uv pip install -r requirements.txt --system\n",
    "!uv pip install WeTextProcessing --system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "\n",
    "The following commands will download the necessary model checkpoints from Hugging Face. You can choose between `huggingface-cli` (recommended) or `wget`.\n",
    "\n",
    "**Important:** You might need to uncomment and run `!pip install huggingface_hub` if `huggingface-cli` is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Using huggingface-cli (Recommended)\n",
    "# Make sure you have huggingface_hub installed and you are logged in if necessary,\n",
    "# though for public models, login might not be required.\n",
    "# !pip install huggingface_hub  # User can uncomment if needed\n",
    "!huggingface-cli download IndexTeam/Index-TTS   bigvgan_discriminator.pth   bigvgan_generator.pth   bpe.model   dvae.pth   gpt.pth   unigram_12000.vocab   --repo-type model   --local-dir checkpoints --local-dir-use-symlinks False\n",
    "\n",
    "# Verify checkpoint files\n",
    "!ls -l checkpoints/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Gradio Web UI\n",
    "\n",
    "This command will start the Gradio web interface. Click the public URL (usually ending with `gradio.live`) that appears in the output to open the UI in your browser.\n",
    "The UI should now be in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the Web UI\n",
    "!python webui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Command-Line Interface (CLI) Usage\n",
    "\n",
    "You can also use IndexTTS via its command-line interface.\n",
    "First, you'll need a reference audio. You can upload one to your Colab environment or use a sample. Let's create a dummy reference for demonstration if you don't have one.\n",
    "\n",
    "**Note:** You'll need to have a `reference_voice.wav` file in the main `index-tts` directory for the example below to work, or modify the path.\n",
    "You might need to stop the Web UI cell above to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Example) Create a dummy reference voice file if you don't have one\n",
    "# This is just a placeholder. Replace with your actual reference audio.\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# samplerate = 22050\n",
    "# duration = 1\n",
    "# frequency = 440\n",
    "# t = np.linspace(0., duration, int(samplerate * duration), endpoint=False)\n",
    "# data = 0.5 * np.sin(2. * np.pi * frequency * t)\n",
    "# sf.write('reference_voice.wav', data, samplerate)\n",
    "\n",
    "# Install IndexTTS as a package for CLI usage\n",
    "!pip install -e .\n",
    "\n",
    "# Run CLI inference (make sure 'reference_voice.wav' exists or change path)\n",
    "# !indextts \"Hello, this is a test of the IndexTTS command line interface.\" \\\n",
    "#   --voice reference_voice.wav \\\n",
    "#   --model_dir checkpoints \\\n",
    "#   --config checkpoints/config.yaml \\\n",
    "#   --output output_cli.wav\n",
    "\n",
    "# print(\"If successful, output_cli.wav should be generated.\")\n",
    "# You can then listen to it or download it from the file browser on the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Python Script Usage\n",
    "\n",
    "You can also use IndexTTS directly in Python.\n",
    "\n",
    "**Note:** You might need to stop the Web UI cell above to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from indextts.infer import IndexTTS\n",
    "\n",
    "# # Ensure you have a reference voice, e.g., 'reference_voice.wav'\n",
    "# # This assumes 'reference_voice.wav' is in the current directory (index-tts)\n",
    "# reference_audio_path = \"reference_voice.wav\" \n",
    "# text_to_speak = \"This is a sample sentence generated using the IndexTTS Python interface.\"\n",
    "# output_file_path = \"output_script.wav\"\n",
    "\n",
    "# if 'tts' not in locals(): # Avoid re-initializing if already done\n",
    "#   tts = IndexTTS(model_dir=\"checkpoints\",cfg_path=\"checkpoints/config.yaml\")\n",
    "\n",
    "# # Check if reference_voice.wav exists, if not, skip inference\n",
    "# import os\n",
    "# if os.path.exists(reference_audio_path):\n",
    "#   tts.infer(reference_audio_path, text_to_speak, output_file_path)\n",
    "#   print(f\"Generated audio saved to {output_file_path}\")\n",
    "#   # You can play/download this file from Colab's file browser\n",
    "# else:\n",
    "#   print(f\"Reference audio {reference_audio_path} not found. Skipping script inference demo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
