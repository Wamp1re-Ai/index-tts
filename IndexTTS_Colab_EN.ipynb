{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Colab_EN.ipynb)\n",
    "[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Colab_EN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndexTTS: Zero-Shot Text-To-Speech on Colab/Kaggle (English UI)\n",
    "\n",
    "This notebook allows you to run the IndexTTS system in Google Colab or Kaggle. It will clone the repository, install dependencies, download models, and start the Gradio web UI. The UI will be in English.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Works on both Google Colab and Kaggle\n",
    "- ‚úÖ English UI with full internationalization support\n",
    "- ‚úÖ Automatic environment detection and optimization\n",
    "- ‚úÖ Fast dependency installation with UV package manager\n",
    "- ‚úÖ Pre-configured model downloads from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Detection and Setup\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Detect environment\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "IN_KAGGLE = 'kaggle_secrets' in sys.modules or os.path.exists('/kaggle')\n",
    "\n",
    "print(f\"Environment detected:\")\n",
    "print(f\"- Google Colab: {IN_COLAB}\")\n",
    "print(f\"- Kaggle: {IN_KAGGLE}\")\n",
    "\n",
    "# Clone the IndexTTS repository\n",
    "!git clone https://github.com/Wamp1re-Ai/index-tts.git\n",
    "%cd index-tts\n",
    "\n",
    "# Switch to the English support branch\n",
    "!git checkout feat/english-colab-notebook\n",
    "\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "This step installs `ffmpeg` (required for audio processing) and all the Python packages listed in `requirements.txt`. The installation is optimized for both Colab and Kaggle environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "if IN_COLAB or IN_KAGGLE:\n",
    "    !apt-get update && apt-get install -y ffmpeg\n",
    "else:\n",
    "    print(\"Please ensure ffmpeg is installed on your system\")\n",
    "\n",
    "# Install uv for faster package installation\n",
    "!pip install uv\n",
    "\n",
    "# Install Python dependencies using uv\n",
    "# Note: WeTextProcessing is required for text normalization\n",
    "# pynini might have installation issues on some platforms\n",
    "try:\n",
    "    !uv pip install -r requirements.txt --system\n",
    "    print(\"‚úÖ Successfully installed requirements.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error installing requirements.txt: {e}\")\n",
    "    print(\"Trying alternative installation method...\")\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "# Install WeTextProcessing separately for better error handling\n",
    "try:\n",
    "    !uv pip install WeTextProcessing --system\n",
    "    print(\"‚úÖ Successfully installed WeTextProcessing\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error installing WeTextProcessing: {e}\")\n",
    "    print(\"Trying with pip...\")\n",
    "    !pip install WeTextProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "\n",
    "The following commands will download the necessary model checkpoints from Hugging Face. This works on both Colab and Kaggle environments.\n",
    "\n",
    "**Note:** The models are approximately 2GB in total. Download time depends on your internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure huggingface_hub is installed\n",
    "!pip install huggingface_hub\n",
    "\n",
    "# Download models using huggingface-cli\n",
    "print(\"üì• Downloading IndexTTS models from Hugging Face...\")\n",
    "print(\"This may take a few minutes depending on your connection.\")\n",
    "\n",
    "!huggingface-cli download IndexTeam/Index-TTS \\\n",
    "    bigvgan_discriminator.pth \\\n",
    "    bigvgan_generator.pth \\\n",
    "    bpe.model \\\n",
    "    dvae.pth \\\n",
    "    gpt.pth \\\n",
    "    unigram_12000.vocab \\\n",
    "    --repo-type model \\\n",
    "    --local-dir checkpoints \\\n",
    "    --local-dir-use-symlinks False\n",
    "\n",
    "print(\"‚úÖ Model download completed!\")\n",
    "\n",
    "# Verify checkpoint files\n",
    "print(\"\\nüìÅ Verifying downloaded files:\")\n",
    "!ls -l checkpoints/\n",
    "\n",
    "# Check if all required files are present\n",
    "import os\n",
    "required_files = [\n",
    "    'bigvgan_discriminator.pth',\n",
    "    'bigvgan_generator.pth', \n",
    "    'bpe.model',\n",
    "    'dvae.pth',\n",
    "    'gpt.pth',\n",
    "    'unigram_12000.vocab',\n",
    "    'config.yaml'\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "for file in required_files:\n",
    "    if not os.path.exists(f'checkpoints/{file}'):\n",
    "        missing_files.append(file)\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ö†Ô∏è  Missing files: {missing_files}\")\n",
    "else:\n",
    "    print(\"‚úÖ All required model files are present!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Gradio Web UI with Public Access\n",
    "\n",
    "This will start the Gradio web interface with English UI and set up public URL access using Cloudflare tunnels.\n",
    "\n",
    "### üåê Public URL Options:\n",
    "\n",
    "**For Colab:**\n",
    "- üîó **Primary**: Colab's built-in public URL (ending with `gradio.live`)\n",
    "- üåç **Backup**: Cloudflare tunnel URL (ending with `trycloudflare.com`)\n",
    "\n",
    "**For Kaggle:**\n",
    "- üåç **Primary**: Cloudflare tunnel URL (ending with `trycloudflare.com`)\n",
    "- üì± **Fallback**: Kaggle's output panel\n",
    "\n",
    "### ‚ú® Features:\n",
    "- ‚úÖ **English UI** with full internationalization support\n",
    "- ‚úÖ **Public URLs** accessible from anywhere\n",
    "- ‚úÖ **No registration required** for Cloudflare tunnels\n",
    "- ‚úÖ **Automatic setup** - just run the cell below\n",
    "\n",
    "### üîí Security Note:\n",
    "The public URLs are temporary and will expire when the notebook session ends. Do not share sensitive information through these interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup public tunnel access with ngrok (primary) and Cloudflare (fallback)\n",
    "import os\n",
    "import subprocess\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# Set environment variables for optimal performance\n",
    "os.environ['GRADIO_SERVER_NAME'] = '0.0.0.0'\n",
    "os.environ['GRADIO_SERVER_PORT'] = '7860'\n",
    "\n",
    "# Ensure English language is set\n",
    "os.environ['LANG'] = 'en_US.UTF-8'\n",
    "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
    "\n",
    "print(\"üöÄ Starting IndexTTS Web UI with English interface...\")\n",
    "print(\"üåê Setting up reliable public URL access...\")\n",
    "print(\"üéØ Using ngrok (primary) + Cloudflare (fallback) for maximum reliability\")\n",
    "\n",
    "# Setup ngrok tunnel (more reliable)\n",
    "def setup_ngrok_tunnel():\n",
    "    try:\n",
    "        # Install ngrok\n",
    "        print(\"üì¶ Installing ngrok for reliable public URL access...\")\n",
    "        !wget -q https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
    "        !tar xzf ngrok-v3-stable-linux-amd64.tgz\n",
    "        !mv ngrok /usr/local/bin/ngrok\n",
    "        !chmod +x /usr/local/bin/ngrok\n",
    "        print(\"‚úÖ ngrok installed successfully\")\n",
    "        \n",
    "        # Start ngrok tunnel\n",
    "        def start_ngrok():\n",
    "            time.sleep(8)  # Wait for Gradio to start\n",
    "            try:\n",
    "                print(\"\\nüöÄ Starting ngrok tunnel...\")\n",
    "                print(\"‚è≥ This usually takes 10-20 seconds...\")\n",
    "                \n",
    "                process = subprocess.Popen([\n",
    "                    'ngrok', 'http', '7860', '--log=stdout'\n",
    "                ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)\n",
    "                \n",
    "                # Monitor output for tunnel URL\n",
    "                start_time = time.time()\n",
    "                timeout = 45\n",
    "                \n",
    "                while time.time() - start_time < timeout:\n",
    "                    line = process.stdout.readline()\n",
    "                    if line:\n",
    "                        line = line.strip()\n",
    "                        print(f\"[ngrok] {line}\")\n",
    "                        \n",
    "                        # Look for ngrok URL\n",
    "                        if 'url=' in line and 'ngrok' in line:\n",
    "                            parts = line.split('url=')\n",
    "                            if len(parts) > 1:\n",
    "                                url = parts[1].split()[0]\n",
    "                                if url.startswith('http') and 'ngrok' in url:\n",
    "                                    print(f\"\\nüéâ SUCCESS! ngrok tunnel is ready!\")\n",
    "                                    print(f\"üîó ngrok URL: {url}\")\n",
    "                                    print(f\"üåç Share this URL with anyone: {url}\")\n",
    "                                    print(f\"üì± Your IndexTTS is now publicly accessible!\")\n",
    "                                    print(f\"‚ú® ngrok is more reliable than Cloudflare tunnels\\n\")\n",
    "                                    return\n",
    "                        \n",
    "                        # Alternative format\n",
    "                        if 'Forwarding' in line and 'ngrok' in line:\n",
    "                            parts = line.split()\n",
    "                            for part in parts:\n",
    "                                if part.startswith('http') and 'ngrok' in part:\n",
    "                                    print(f\"\\nüéâ SUCCESS! ngrok tunnel is ready!\")\n",
    "                                    print(f\"üîó ngrok URL: {part}\")\n",
    "                                    print(f\"üåç Share this URL with anyone: {part}\")\n",
    "                                    print(f\"üì± Your IndexTTS is now publicly accessible!\\n\")\n",
    "                                    return\n",
    "                    \n",
    "                    if process.poll() is not None:\n",
    "                        break\n",
    "                        \n",
    "                    time.sleep(0.5)\n",
    "                \n",
    "                print(\"‚è∞ ngrok tunnel setup timeout\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  ngrok tunnel error: {e}\")\n",
    "        \n",
    "        # Start ngrok in background\n",
    "        ngrok_thread = threading.Thread(target=start_ngrok, daemon=True)\n",
    "        ngrok_thread.start()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  ngrok setup failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Setup Cloudflare as fallback\n",
    "def setup_cloudflare_fallback():\n",
    "    try:\n",
    "        print(\"\\nüîÑ Also setting up Cloudflare tunnel as backup...\")\n",
    "        !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
    "        !dpkg -i cloudflared-linux-amd64.deb\n",
    "        \n",
    "        def start_cloudflare():\n",
    "            time.sleep(15)  # Wait a bit longer\n",
    "            try:\n",
    "                print(\"\\nüåê Starting Cloudflare tunnel as backup...\")\n",
    "                process = subprocess.Popen([\n",
    "                    'cloudflared', 'tunnel', '--url', 'http://localhost:7860'\n",
    "                ], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1)\n",
    "                \n",
    "                for line in iter(process.stdout.readline, ''):\n",
    "                    line = line.strip()\n",
    "                    if line and 'trycloudflare.com' in line:\n",
    "                        words = line.split()\n",
    "                        for word in words:\n",
    "                            if word.startswith('http') and 'trycloudflare.com' in word:\n",
    "                                print(f\"\\nüîó Backup Cloudflare URL: {word}\")\n",
    "                                return\n",
    "                                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Cloudflare backup failed: {e}\")\n",
    "        \n",
    "        cf_thread = threading.Thread(target=start_cloudflare, daemon=True)\n",
    "        cf_thread.start()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Cloudflare backup setup failed: {e}\")\n",
    "\n",
    "# Setup tunnels\n",
    "ngrok_success = setup_ngrok_tunnel()\n",
    "setup_cloudflare_fallback()  # Always setup as backup\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üîó Colab will also provide a gradio.live URL\")\n",
    "    if ngrok_success:\n",
    "        print(\"üåê ngrok tunnel will provide the most reliable public URL (see above)\")\n",
    "        print(\"üîÑ Cloudflare tunnel available as backup\")\n",
    "elif IN_KAGGLE:\n",
    "    if ngrok_success:\n",
    "        print(\"üåê Public access via ngrok tunnel (see above)\")\n",
    "    else:\n",
    "        print(\"üîó Interface will be available in Kaggle's output panel\")\n",
    "\n",
    "print(\"\\nüöÄ Launching IndexTTS...\")\n",
    "print(\"‚è≥ Please wait for the ngrok URL to appear above...\")\n",
    "print(\"üí° ngrok URLs are more reliable than Cloudflare tunnels\")\n",
    "\n",
    "# Run the Web UI with public access\n",
    "!python webui.py --host 0.0.0.0 --port 7860"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Command-Line Interface (CLI) Usage\n",
    "\n",
    "You can also use IndexTTS via its command-line interface.\n",
    "First, you'll need a reference audio. You can upload one to your Colab environment or use a sample. Let's create a dummy reference for demonstration if you don't have one.\n",
    "\n",
    "**Note:** You'll need to have a `reference_voice.wav` file in the main `index-tts` directory for the example below to work, or modify the path.\n",
    "You might need to stop the Web UI cell above to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Example) Create a dummy reference voice file if you don't have one\n",
    "# This is just a placeholder. Replace with your actual reference audio.\n",
    "# import numpy as np\n",
    "# import soundfile as sf\n",
    "# samplerate = 22050\n",
    "# duration = 1\n",
    "# frequency = 440\n",
    "# t = np.linspace(0., duration, int(samplerate * duration), endpoint=False)\n",
    "# data = 0.5 * np.sin(2. * np.pi * frequency * t)\n",
    "# sf.write('reference_voice.wav', data, samplerate)\n",
    "\n",
    "# Install IndexTTS as a package for CLI usage\n",
    "!pip install -e .\n",
    "\n",
    "# Run CLI inference (make sure 'reference_voice.wav' exists or change path)\n",
    "# !indextts \"Hello, this is a test of the IndexTTS command line interface.\" \\\n",
    "#   --voice reference_voice.wav \\\n",
    "#   --model_dir checkpoints \\\n",
    "#   --config checkpoints/config.yaml \\\n",
    "#   --output output_cli.wav\n",
    "\n",
    "# print(\"If successful, output_cli.wav should be generated.\")\n",
    "# You can then listen to it or download it from the file browser on the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Python Script Usage\n",
    "\n",
    "You can also use IndexTTS directly in Python.\n",
    "\n",
    "**Note:** You might need to stop the Web UI cell above to run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from indextts.infer import IndexTTS\n",
    "\n",
    "# # Ensure you have a reference voice, e.g., 'reference_voice.wav'\n",
    "# # This assumes 'reference_voice.wav' is in the current directory (index-tts)\n",
    "# reference_audio_path = \"reference_voice.wav\" \n",
    "# text_to_speak = \"This is a sample sentence generated using the IndexTTS Python interface.\"\n",
    "# output_file_path = \"output_script.wav\"\n",
    "\n",
    "# if 'tts' not in locals(): # Avoid re-initializing if already done\n",
    "#   tts = IndexTTS(model_dir=\"checkpoints\",cfg_path=\"checkpoints/config.yaml\")\n",
    "\n",
    "# # Check if reference_voice.wav exists, if not, skip inference\n",
    "# import os\n",
    "# if os.path.exists(reference_audio_path):\n",
    "#   tts.infer(reference_audio_path, text_to_speak, output_file_path)\n",
    "#   print(f\"Generated audio saved to {output_file_path}\")\n",
    "#   # You can play/download this file from Colab's file browser\n",
    "# else:\n",
    "#   print(f\"Reference audio {reference_audio_path} not found. Skipping script inference demo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
