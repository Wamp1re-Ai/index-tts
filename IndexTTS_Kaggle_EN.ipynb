{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Kaggle_EN.ipynb)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Wamp1re-Ai/index-tts/blob/feat/english-colab-notebook/IndexTTS_Kaggle_EN.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IndexTTS: Zero-Shot Text-To-Speech on Kaggle (English UI)\n",
    "\n",
    "This notebook is optimized for Kaggle environments and allows you to run the IndexTTS system. It will clone the repository, install dependencies, download models, and start the Gradio web UI with English interface.\n",
    "\n",
    "**Kaggle-Optimized Features:**\n",
    "- ‚úÖ Optimized for Kaggle's environment and resource constraints\n",
    "- ‚úÖ English UI with full internationalization support\n",
    "- ‚úÖ Efficient dependency installation\n",
    "- ‚úÖ Pre-configured model downloads from Hugging Face\n",
    "- ‚úÖ Memory and storage optimizations for Kaggle\n",
    "\n",
    "**Requirements:**\n",
    "- Enable Internet access in Kaggle notebook settings\n",
    "- Recommended: GPU accelerator for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Environment Setup and Repository Clone\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Verify Kaggle environment\n",
    "IN_KAGGLE = 'kaggle_secrets' in sys.modules or os.path.exists('/kaggle')\n",
    "print(f\"Running in Kaggle: {IN_KAGGLE}\")\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    print(\"‚úÖ Kaggle environment detected\")\n",
    "    # Change to working directory\n",
    "    os.chdir('/kaggle/working')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not running in Kaggle - some features may not work as expected\")\n",
    "\n",
    "# Clone the IndexTTS repository\n",
    "print(\"üì• Cloning IndexTTS repository...\")\n",
    "!git clone https://github.com/Wamp1re-Ai/index-tts.git\n",
    "%cd index-tts\n",
    "\n",
    "# Switch to the English support branch\n",
    "!git checkout feat/english-colab-notebook\n",
    "\n",
    "print(\"‚úÖ Repository cloned successfully\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "This step installs all required dependencies optimized for Kaggle's environment. We use efficient package managers and handle potential installation issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies (ffmpeg is usually pre-installed in Kaggle)\n",
    "print(\"üîß Setting up system dependencies...\")\n",
    "\n",
    "# Check if ffmpeg is available\n",
    "import subprocess\n",
    "try:\n",
    "    result = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ ffmpeg is already available\")\n",
    "    else:\n",
    "        raise Exception(\"ffmpeg not found\")\n",
    "except:\n",
    "    print(\"üì¶ Installing ffmpeg...\")\n",
    "    !apt-get update && apt-get install -y ffmpeg\n",
    "\n",
    "# Install UV for faster package management\n",
    "print(\"üì¶ Installing UV package manager...\")\n",
    "!pip install uv\n",
    "\n",
    "# Install Python dependencies with error handling\n",
    "print(\"üì¶ Installing Python dependencies...\")\n",
    "try:\n",
    "    !uv pip install -r requirements.txt --system\n",
    "    print(\"‚úÖ Successfully installed requirements.txt with UV\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  UV installation failed, trying with pip: {e}\")\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "# Install WeTextProcessing separately for better error handling\n",
    "print(\"üì¶ Installing WeTextProcessing...\")\n",
    "try:\n",
    "    !uv pip install WeTextProcessing --system\n",
    "    print(\"‚úÖ Successfully installed WeTextProcessing\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  UV installation failed, trying with pip: {e}\")\n",
    "    !pip install WeTextProcessing\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Models\n",
    "\n",
    "Download the necessary model checkpoints from Hugging Face. This is optimized for Kaggle's network and storage constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure huggingface_hub is installed\n",
    "!pip install huggingface_hub\n",
    "\n",
    "# Download models using huggingface-cli\n",
    "print(\"üì• Downloading IndexTTS models from Hugging Face...\")\n",
    "print(\"‚è±Ô∏è  This may take 5-10 minutes depending on Kaggle's network speed.\")\n",
    "print(\"üíæ Models are approximately 2GB total.\")\n",
    "\n",
    "# Create checkpoints directory if it doesn't exist\n",
    "!mkdir -p checkpoints\n",
    "\n",
    "# Download with progress tracking\n",
    "!huggingface-cli download IndexTeam/Index-TTS \\\n",
    "    bigvgan_discriminator.pth \\\n",
    "    bigvgan_generator.pth \\\n",
    "    bpe.model \\\n",
    "    dvae.pth \\\n",
    "    gpt.pth \\\n",
    "    unigram_12000.vocab \\\n",
    "    --repo-type model \\\n",
    "    --local-dir checkpoints \\\n",
    "    --local-dir-use-symlinks False\n",
    "\n",
    "print(\"‚úÖ Model download completed!\")\n",
    "\n",
    "# Verify checkpoint files\n",
    "print(\"\\nüìÅ Verifying downloaded files:\")\n",
    "!ls -lh checkpoints/\n",
    "\n",
    "# Check if all required files are present\n",
    "import os\n",
    "required_files = [\n",
    "    'bigvgan_discriminator.pth',\n",
    "    'bigvgan_generator.pth', \n",
    "    'bpe.model',\n",
    "    'dvae.pth',\n",
    "    'gpt.pth',\n",
    "    'unigram_12000.vocab',\n",
    "    'config.yaml'\n",
    "]\n",
    "\n",
    "missing_files = []\n",
    "total_size = 0\n",
    "for file in required_files:\n",
    "    file_path = f'checkpoints/{file}'\n",
    "    if not os.path.exists(file_path):\n",
    "        missing_files.append(file)\n",
    "    else:\n",
    "        size = os.path.getsize(file_path)\n",
    "        total_size += size\n",
    "        print(f\"‚úÖ {file}: {size/1024/1024:.1f} MB\")\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"‚ùå Missing files: {missing_files}\")\n",
    "    print(\"Please re-run the download cell above.\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ All required model files are present!\")\n",
    "    print(f\"üìä Total model size: {total_size/1024/1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Gradio Web UI\n",
    "\n",
    "Start the Gradio web interface optimized for Kaggle. The UI will be displayed in English with full internationalization support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Kaggle-specific settings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set environment variables for optimal performance in Kaggle\n",
    "os.environ['GRADIO_SERVER_NAME'] = '0.0.0.0'\n",
    "os.environ['GRADIO_SERVER_PORT'] = '7860'\n",
    "\n",
    "# Ensure English language is set\n",
    "os.environ['LANG'] = 'en_US.UTF-8'\n",
    "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
    "\n",
    "# Kaggle-specific optimizations\n",
    "os.environ['GRADIO_ANALYTICS_ENABLED'] = 'False'  # Disable analytics for privacy\n",
    "os.environ['GRADIO_SHARE'] = 'False'  # Kaggle handles sharing differently\n",
    "\n",
    "print(\"üöÄ Starting IndexTTS Web UI with English interface...\")\n",
    "print(\"üì± The interface will appear in the output below.\")\n",
    "print(\"üéØ UI Language: English (en_US)\")\n",
    "print(\"‚ö° Environment: Kaggle Optimized\")\n",
    "\n",
    "# Import and check if the TTS system is working\n",
    "try:\n",
    "    from indextts.infer import IndexTTS\n",
    "    print(\"‚úÖ IndexTTS module loaded successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing IndexTTS: {e}\")\n",
    "    print(\"Please ensure all dependencies are installed correctly.\")\n",
    "\n",
    "# Run the Web UI\n",
    "!python webui.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Command-Line Interface Usage\n",
    "\n",
    "You can also use IndexTTS via command-line interface. This section demonstrates CLI usage in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install IndexTTS as a package for CLI usage\n",
    "!pip install -e .\n",
    "\n",
    "# Create a sample reference audio for demonstration\n",
    "# (In practice, you would upload your own reference audio)\n",
    "print(\"üéµ Creating sample reference audio for demonstration...\")\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Generate a simple sine wave as placeholder\n",
    "samplerate = 22050\n",
    "duration = 2  # 2 seconds\n",
    "frequency = 440  # A4 note\n",
    "t = np.linspace(0., duration, int(samplerate * duration), endpoint=False)\n",
    "# Create a more complex waveform\n",
    "data = 0.3 * (np.sin(2. * np.pi * frequency * t) + \n",
    "              0.3 * np.sin(2. * np.pi * frequency * 2 * t) +\n",
    "              0.1 * np.sin(2. * np.pi * frequency * 3 * t))\n",
    "sf.write('sample_reference.wav', data, samplerate)\n",
    "print(\"‚úÖ Sample reference audio created: sample_reference.wav\")\n",
    "\n",
    "# Example CLI usage (commented out - uncomment to test)\n",
    "# !indextts \"Hello, this is a test of the IndexTTS command line interface running on Kaggle.\" \\\n",
    "#   --voice sample_reference.wav \\\n",
    "#   --model_dir checkpoints \\\n",
    "#   --config checkpoints/config.yaml \\\n",
    "#   --output output_cli.wav\n",
    "\n",
    "print(\"\\nüí° To use CLI:\")\n",
    "print(\"1. Upload your reference audio file\")\n",
    "print(\"2. Uncomment and modify the CLI command above\")\n",
    "print(\"3. Run the cell to generate speech\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (Optional) Python API Usage\n",
    "\n",
    "Direct Python API usage example for Kaggle environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Python API usage\n",
    "# Uncomment the code below to test direct API usage\n",
    "\n",
    "# from indextts.infer import IndexTTS\n",
    "# import os\n",
    "\n",
    "# # Initialize TTS system\n",
    "# print(\"üîß Initializing IndexTTS system...\")\n",
    "# tts = IndexTTS(model_dir=\"checkpoints\", cfg_path=\"checkpoints/config.yaml\")\n",
    "\n",
    "# # Use the sample reference audio we created\n",
    "# reference_audio_path = \"sample_reference.wav\"\n",
    "# text_to_speak = \"This is a sample sentence generated using IndexTTS Python API in Kaggle environment.\"\n",
    "# output_file_path = \"output_api.wav\"\n",
    "\n",
    "# if os.path.exists(reference_audio_path):\n",
    "#     print(f\"üéØ Generating speech for: '{text_to_speak}'\")\n",
    "#     tts.infer(reference_audio_path, text_to_speak, output_file_path)\n",
    "#     print(f\"‚úÖ Generated audio saved to {output_file_path}\")\n",
    "#     \n",
    "#     # Display audio player\n",
    "#     import IPython.display as ipd\n",
    "#     print(\"üéµ Generated Audio:\")\n",
    "#     ipd.display(ipd.Audio(output_file_path))\n",
    "# else:\n",
    "#     print(f\"‚ùå Reference audio {reference_audio_path} not found.\")\n",
    "\n",
    "print(\"üí° Uncomment the code above to test the Python API directly.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
